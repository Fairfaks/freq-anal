# -*- coding: utf-8 -*-
"""
–ß–∞—Å—Ç–æ—Ç–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –ø—Ä–æ–¥–≤–∏–≥–∞–µ–º–æ–≥–æ —Å–∞–π—Ç–∞ vs –∫–æ–Ω–∫—É—Ä–µ–Ω—Ç–æ–≤ + —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ —Å –∫–æ—Ä–ø—É—Å–æ–º + —ç–∫—Å–ø–æ—Ä—Ç –≤ Excel.
–î–æ–±–∞–≤–ª–µ–Ω –ª–∏—Å—Ç ¬´Comparison¬ª —Å —É—Å–ª–æ–≤–Ω—ã–º —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ–º.
–ó–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏:
    pip install requests beautifulsoup4 lxml nltk pymorphy2 pandas numpy tqdm openpyxl xlsxwriter
"""

import inspect, os, csv, requests, re, nltk, pymorphy2
import pandas as pd, numpy as np
from bs4 import BeautifulSoup
from collections import Counter
from tqdm import tqdm

# --- –ü–∞—Ç—á –¥–ª—è pymorphy2 + Python 3.11+ ---
def _getargspec(func):
    spec = inspect.getfullargspec(func)
    return spec.args, spec.varargs, spec.varkw, spec.defaults
inspect.getargspec = _getargspec

# --- –°—Ç–æ–ø-—Å–ª–æ–≤–∞ NLTK ---
nltk.download('stopwords', quiet=True)
from nltk.corpus import stopwords

def get_page_text(url: str) -> str:
    headers = {
        'User-Agent': (
            'Mozilla/5.0 (Windows NT 10.0; Win64; x64) '
            'AppleWebKit/537.36 (KHTML, like Gecko) '
            'Chrome/114.0.0.0 Safari/537.36'
        ),
        'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8',
        'Accept-Language': 'ru-RU,ru;q=0.9',
        'Connection': 'keep-alive','Referer': url,
    }
    resp = requests.get(url, headers=headers, timeout=30)
    resp.raise_for_status()
    soup = BeautifulSoup(resp.text, 'lxml')
    for tag in soup(['script','style','nav','header','footer','aside']):
        tag.decompose()
    return soup.body.get_text(separator=' ', strip=True) if soup.body else soup.get_text()

def tokenize_morph(text: str):
    tokens = re.findall(r'\b[–∞-—è—ë]+\b', text.lower())
    morph = pymorphy2.MorphAnalyzer()
    stop_ru = set(stopwords.words('russian'))
    out = []
    for w in tqdm(tokens, desc="  –º–æ—Ä—Ñ–æ-—Ç–æ–∫–µ–Ω—ã", unit="—Ç–æ–∫–µ–Ω"):
        if w in stop_ru or len(w)<3: continue
        p = morph.parse(w)[0]
        out.append({'word':w,'lemma':p.normal_form,'pos':p.tag.POS or ''})
    return out

def build_target_freq(morph_data, top_n=100):
    total = len(morph_data)
    cnt = Counter(item['word'] for item in morph_data)
    rows = []
    for word,freq in cnt.most_common(top_n):
        info = next(item for item in morph_data if item['word']==word)
        rows.append({
            '–°–ª–æ–≤–æ':word,
            '–õ–µ–º–º–∞':info['lemma'],
            '–ß–∞—Å—Ç—å —Ä–µ—á–∏':info['pos'],
            '–ß–∞—Å—Ç–æ—Ç–∞':freq,
            '%_target':round(freq/total*100,3)
        })
    return pd.DataFrame(rows)

def load_corpus(path: str) -> pd.DataFrame:
    with open(path,'r',encoding='utf-8-sig') as f:
        sample = f.read(2048)
        delim = csv.Sniffer().sniff(sample, delimiters=[',',';','\t','|']).delimiter
    reader = pd.read_csv(path, sep=delim, engine='python',
                         encoding='utf-8-sig',
                         usecols=lambda c: c.strip() in ('word','freq_corpus'),
                         skipinitialspace=True, chunksize=100_000)
    chunks, total = [], 0
    for chunk in tqdm(reader, desc="  —á—Ç–µ–Ω–∏–µ –∫–æ—Ä–ø—É—Å–∞", unit="—Å—Ç—Ä–æ–∫"):
        chunk.columns = chunk.columns.str.strip()
        chunks.append(chunk)
        total += chunk['freq_corpus'].sum()
    df = pd.concat(chunks, ignore_index=True)
    df['percent_corpus'] = df['freq_corpus']/total*100
    return df.rename(columns={'word':'–õ–µ–º–º–∞'})[['–õ–µ–º–º–∞','percent_corpus']]

if __name__=='__main__':
    script_dir = os.path.dirname(os.path.abspath(__file__))

    # 1) –í–≤–æ–¥ URL –ø—Ä–æ–¥–≤–∏–≥–∞–µ–º–æ–≥–æ —Å–∞–π—Ç–∞
    main_url = input("–í–≤–µ–¥–∏—Ç–µ URL –ø—Ä–æ–¥–≤–∏–≥–∞–µ–º–æ–≥–æ —Å–∞–π—Ç–∞: ").strip()

    # 2) –í–≤–æ–¥ URL –∫–æ–Ω–∫—É—Ä–µ–Ω—Ç–æ–≤
    raw = input("–í–≤–µ–¥–∏—Ç–µ URL –∫–æ–Ω–∫—É—Ä–µ–Ω—Ç–æ–≤ —á–µ—Ä–µ–∑ –∑–∞–ø—è—Ç—É—é: ").split(',')
    comp_urls = [u.strip() for u in raw if u.strip()]

    # 3) –û–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ —Å–∫–∞—á–∏–≤–∞–µ–º –∫–æ—Ä–ø—É—Å HermitDave
    if input("–°–∫–∞—á–∞—Ç—å –∫–æ—Ä–ø—É—Å HermitDave? (–î–∞/–ù–µ—Ç): ").strip().lower() in ('–¥–∞','–¥','yes','y'):
        hd_url = 'https://raw.githubusercontent.com/hermitdave/FrequencyWords/master/content/2016/ru/ru_full.txt'
        print("‚è≥ –°–∫–∞—á–∏–≤–∞–µ–º HermitDave...")
        r = requests.get(hd_url, timeout=60); r.raise_for_status()
        lines = r.text.splitlines()
        out = os.path.join(script_dir,'russian_freq.csv')
        with open(out,'w',encoding='utf-8') as f:
            f.write('word,freq_corpus\n')
            for L in lines:
                p = L.split()
                if len(p)>=2: f.write(f"{p[0]},{p[1]}\n")
        print("‚úÖ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ ‚Üí", out)

    # 4) –í—ã–±–æ—Ä –∫–æ—Ä–ø—É—Å–∞
    csvs = [f for f in os.listdir(script_dir) if f.lower().endswith('.csv')]
    print("\n–î–æ—Å—Ç—É–ø–Ω—ã–µ CSV –∫–æ—Ä–ø—É—Å–∞:")
    for i,fn in enumerate(csvs,1): print(f"  {i}. {fn}")
    idx = int(input(f"–í—ã–±–µ—Ä–∏—Ç–µ –∫–æ—Ä–ø—É—Å (1‚Äì{len(csvs)}): ").strip())-1
    corpus_df = load_corpus(os.path.join(script_dir, csvs[idx]))

    # 5) –ê–Ω–∞–ª–∏–∑ –ø—Ä–æ–¥–≤–∏–≥–∞–µ–º–æ–≥–æ —Å–∞–π—Ç–∞
    print(f"\nüîç –ê–Ω–∞–ª–∏–∑ –ø—Ä–æ–¥–≤–∏–≥–∞–µ–º–æ–≥–æ —Å–∞–π—Ç–∞: {main_url}")
    main_text = get_page_text(main_url)
    main_morph = tokenize_morph(main_text)
    df_main = build_target_freq(main_morph, top_n=100)
    df_main['URL'] = main_url

    # 6) –ê–Ω–∞–ª–∏–∑ –∫–æ–Ω–∫—É—Ä–µ–Ω—Ç–æ–≤
    results_comp = {}
    for url in comp_urls:
        print(f"\nüîç –ê–Ω–∞–ª–∏–∑ –∫–æ–Ω–∫—É—Ä–µ–Ω—Ç–∞: {url}")
        text = get_page_text(url)
        morph = tokenize_morph(text)
        df = build_target_freq(morph, top_n=100)
        df['URL'] = url
        results_comp[url] = df

    # 7) –û–±—ä–µ–¥–∏–Ω—è–µ–º –≤—Å–µ –≤ –æ–¥–∏–Ω DataFrame
    all_df = pd.concat([df_main] + list(results_comp.values()), ignore_index=True)
    merged = all_df.merge(corpus_df, how='left', on='–õ–µ–º–º–∞')
    mz = merged['percent_corpus'][merged['percent_corpus']>0].min()
    merged['percent_corpus'] = merged['percent_corpus'].fillna(mz)
    merged['%_corpus']  = merged['percent_corpus'].round(3)
    merged['Ratio']     = (merged['%_target']/merged['%_corpus']).round(3)
    merged['Log(Ratio)']= np.log(merged['Ratio']).round(3)

    # 8) –û–±—â–∏–µ –∏ —É–Ω–∏–∫–∞–ª—å–Ω—ã–µ –ª–µ–º–º—ã
    all_urls = [main_url] + comp_urls
    n_pages = len(all_urls)

    # 8.1) –û–±—â–∏–µ –ª–µ–º–º—ã
    common = (
        merged
        .groupby('–õ–µ–º–º–∞')['URL']
        .nunique()
        .reset_index(name='pages')
    )
    common = common[common['pages'] == n_pages].drop(columns='pages')

    # 8.2) –£–Ω–∏–∫–∞–ª—å–Ω—ã–µ –ª–µ–º–º—ã
    unique = {}
    for url in all_urls:
        df_url = merged[merged['URL'] == url]
        others = set(merged.loc[merged['URL'] != url, '–õ–µ–º–º–∞'])
        unique[url] = df_url[~df_url['–õ–µ–º–º–∞'].isin(others)].copy()

    # 9) –°—Ä–µ–¥–Ω–∏–µ –ø–æ –∫–æ–Ω–∫—É—Ä–µ–Ω—Ç–∞–º: –ê–±—Å–æ–ª—é—Ç–Ω–∞—è, –û—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–∞—è –∏ Ratio
    comp_merged = merged[merged['URL'].isin(comp_urls)]
    comp_stats = comp_merged.groupby('–õ–µ–º–º–∞').agg({
        '–ß–∞—Å—Ç–æ—Ç–∞': 'mean',
        '%_target': 'mean',
        'Ratio': 'mean'
    }).rename(columns={
        '–ß–∞—Å—Ç–æ—Ç–∞': '–ß–∞—Å—Ç–æ—Ç–∞_comp_avg',
        '%_target': '%_target_comp_avg',
        'Ratio': 'Ratio_comp_avg'
    }).reset_index()
    # –æ–∫—Ä—É–≥–ª—è–µ–º
    comp_stats['–ß–∞—Å—Ç–æ—Ç–∞_comp_avg'] = comp_stats['–ß–∞—Å—Ç–æ—Ç–∞_comp_avg'].round(2)
    comp_stats['%_target_comp_avg'] = comp_stats['%_target_comp_avg'].round(3)
    comp_stats['Ratio_comp_avg'] = comp_stats['Ratio_comp_avg'].round(3)

    # 10) –§–æ—Ä–º–∏—Ä—É–µ–º Comparison-–¥–∞—Ç–∞—Ñ—Ä–µ–π–º
    comp_df = df_main.merge(comp_stats, on='–õ–µ–º–º–∞', how='left')

    # 11) –≠–∫—Å–ø–æ—Ä—Ç –≤—Å–µ—Ö –ª–∏—Å—Ç–æ–≤ –≤ –æ–¥–∏–Ω —Ñ–∞–π–ª
    out_xlsx = os.path.join(script_dir, 'multi_page_analysis.xlsx')
    with pd.ExcelWriter(out_xlsx, engine='xlsxwriter') as writer:
        # 11.1) –õ–∏—Å—Ç —Å–æ –≤—Å–µ–º–∏ –¥–∞–Ω–Ω—ã–º–∏
        merged.to_excel(writer, sheet_name='All', index=False)

        # 11.2) –õ–∏—Å—Ç —Å –æ–±—â–∏–º–∏ –ª–µ–º–º–∞–º–∏
        common.to_excel(writer, sheet_name='Common', index=False)

        # 11.3) –õ–∏—Å—Ç—ã —Å —É–Ω–∏–∫–∞–ª—å–Ω—ã–º–∏ –ª–µ–º–º–∞–º–∏
        prefix = 'Unique_'
        max_raw = 31 - len(prefix)  # –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ –¥–æ–ø—É—Å—Ç–∏–º–∞—è –¥–ª–∏–Ω–∞ ¬´—Å—ã—Ä—ã—Ö¬ª —Å–∏–º–≤–æ–ª–æ–≤
        for url, df_u in unique.items():
            raw = url.replace('https://', '') \
                .replace('http://', '') \
                .replace('/', '_')
            sheet_name = prefix + raw[:max_raw]
            df_u.to_excel(writer, sheet_name=sheet_name, index=False)

        # 11.4) –õ–∏—Å—Ç Comparison
        comp_df.to_excel(writer, sheet_name='Comparison', index=False)

        # 11.5) –£—Å–ª–æ–≤–Ω–æ–µ —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –Ω–∞ –ª–∏—Å—Ç–µ Comparison
        workbook = writer.book
        worksheet = writer.sheets['Comparison']
        fmt_green = workbook.add_format({'bg_color': '#C6EFCE', 'font_color': '#006100'})
        fmt_red = workbook.add_format({'bg_color': '#FFC7CE', 'font_color': '#9C0006'})
        fmt_yellow = workbook.add_format({'bg_color': '#FFEB9C', 'font_color': '#9C6500'})
        nrows = len(comp_df) + 1

        # –ø–æ–¥—Å–≤–µ—Ç–∫–∞ –∞–±—Å–æ–ª—é—Ç–Ω—ã—Ö —á–∞—Å—Ç–æ—Ç: D (main) vs E (comp_avg)
        worksheet.conditional_format(f'D2:D{nrows}', {
            'type': 'formula', 'criteria': '=D2>E2', 'format': fmt_green})
        worksheet.conditional_format(f'D2:D{nrows}', {
            'type': 'formula', 'criteria': '=D2<E2', 'format': fmt_red})
        worksheet.conditional_format(f'D2:D{nrows}', {
            'type': 'formula', 'criteria': '=D2=E2', 'format': fmt_yellow})

        # –ø–æ–¥—Å–≤–µ—Ç–∫–∞ –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω—ã—Ö —á–∞—Å—Ç–æ—Ç: F (main) vs G (comp_avg)
        worksheet.conditional_format(f'F2:F{nrows}', {
            'type': 'formula', 'criteria': '=F2>G2', 'format': fmt_green})
        worksheet.conditional_format(f'F2:F{nrows}', {
            'type': 'formula', 'criteria': '=F2<G2', 'format': fmt_red})
        worksheet.conditional_format(f'F2:F{nrows}', {
            'type': 'formula', 'criteria': '=F2=G2', 'format': fmt_yellow})

    print(f"\n‚úÖ –ê–Ω–∞–ª–∏–∑ –∑–∞–≤–µ—Ä—à—ë–Ω. –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –≤ {out_xlsx}")
